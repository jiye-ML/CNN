## 学习过程中一些经验和遇到的问题



* [构建深度神经网络，我有20条「不成熟」的小建议](https://mp.weixin.qq.com/s/miKs4tWu8Hh1yHvx-XZFwg)
    * 激励层的实践经验：
        * 不要用sigmoid！不要用sigmoid！不要用sigmoid！
        * 首先试RELU，因为快，但要小心点
        * 如果2失效，请用Leaky ReLU或者Maxout
        * 某些情况下tanh倒是有不错的结果，但是很少