## Tips for Hyperparameter Optimization

- k-fold交叉验证。您可以看到本文中示例的结果显示出一些差异。使用默认的交叉验证3，但是k = 5或k = 10可能更稳定。仔细选择交叉验证配置以确保结果稳定。
- 查看整个网格。不要只关注最佳结果，检查整个结果网格并寻找支持配置决策的趋势。
- 并行。如果可以的话，使用你所有的核心，神经网络训练很慢，我们经常想尝试很多不同的参数。考虑搞砸很多AWS实例。
- 使用数据集的样本。因为网络训练很慢，所以尝试在训练数据集的较小样本上训练它们，只是为了了解参数的一般方向而不是最佳配置。
- 从粗网格开始。从粗粒度网格开始，一旦缩小范围，就可以缩放到更细粒度的网格。
- 不要转移结果。结果通常是特定于问题的。尝试在您看到的每个新问题上避免喜欢的配置。您在一个问题上发现的最佳结果不太可能转移到您的下一个项目。而是寻找更广泛的趋势，例如层数或参数之间的关系。
- 再现性是一个问题。虽然我们在NumPy中为随机数生成器设置种子，但结果不是100％可重复的。当网格搜索包裹Keras模型时，重复性要高于本文中提供的内容。