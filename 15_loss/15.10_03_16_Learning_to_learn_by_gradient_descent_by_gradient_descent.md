## who

* [paper]()
* 发表在2016年的NIPS
* [转自-Learning to learn by gradient descent by gradient descent - PyTorch实践](https://blog.csdn.net/senius/article/details/84483329)

* [GitHub](https://github.com/jiye-ML/DeepLearning-01-200-learning-to-learn.git)

## what

* Learning to learn，即学会学习，是每个人都具备的能力，具体指的是一种在学习的过程中去反思自己的学习行为来进一步提升学习能力的能力。
* 这在日常生活中其实很常见，比如在通过一本书来学习某个陌生专业的领域知识时（如《机器学习》），面对大量的专业术语与陌生的公式符号，初学者很容易看不下去，而比较好的方法就是先浏览目录，掌握一些简单的概念（回归与分类啊，监督与无监督啊），并在按顺序的阅读过程学会“前瞻”与“回顾”，进行快速学习。又比如在早期接受教育的学习阶段，盲目的“题海战术”或死记硬背的“知识灌输”如果不加上恰当的反思和总结，往往会耗时耗力，最后达到的效果却一般，这是因为在接触新东西，掌握新技能时，是需要“技巧性”的。

* 从学习知识到学习策略的层面上，总会有“最强王者”在告诉我们，“钻石的操作、黄铜的意识”也许并不能取胜，要“战略上最佳，战术上谨慎”才能更快更好地进步。

这跟本文要讲的内容有什么关系呢？进入正题。

> 其实读者可以先回顾自己从初高中到大学甚至研究生的整个历程，是不是发现自己已经具备了“learning to learn”的能力？

Learning to learn by gradient descent
“通过梯度下降来学习如何通过梯度下降学习”

>  是否可以让优化器学会 “为了更好地得到，要先去舍弃” 这样的“策略”？

* 首先别被论文题目给误导，它不是求梯度的梯度，这里不涉及到二阶导的任何操作，而是跟如何学会更好的优化有关，正确的断句方法为learning to (learn by gradient descent ) by gradient descent 。

* 第一次读完后，不禁惊叹作者巧妙的构思–使用LSTM（long short-term memory）优化器来替代传统优化器如（SGD，RMSProp，Adam等），然后使用梯度下降来优化优化器本身。

* 虽然明白了作者的出发点，但总感觉一些细节自己没有真正理解。然后就去看原作的代码实现，读起来也是很费劲。查阅了一些博客，但网上对这篇论文解读很少，停留于论文翻译理解上。再次揣摩论文后，打算做一些实验来理解。 在用PyTorch写代码的过程，才恍然大悟，作者的思路是如此简单巧妙，论文名字起的也很恰当，没在故弄玄虚，但是在实现的过程却费劲了周折！

* 如果想看最终版代码和结果，可以直接跳到文档的最后！！！

* 下面写的一些文字与代码主要站在我自身的角度，记录自己在学习研究这篇论文和代码过程中的所有历程，如何想的，遇到了什么错误，问题在哪里，我把自己理解领悟“learning to learn”这篇论文的过程剖析了一下，也意味着我自己也在“learning to learn”！为了展现自己的心路历程，我基本保留了所有的痕迹，这意味着有些代码不够整洁，不过文档的最后是最终简洁完整版。
  提醒：看完整个文档需要大量的耐心 : )

  我默认读者已经掌握了一些必要知识，也希望通过回顾这些经典研究给自己和一些读者带来切实的帮助和启发。

* 用Pytorch实现这篇论文想法其实很方便，但是论文作者来自DeepMind，他们用[Tensorflow写的项目](https://github.com/deepmind/learning-to-learn)，读他们的代码你就会领教到最前沿的一线AI工程师们是如何进行工程实践的。

> 下面进入正题，我会按照最简单的思路，循序渐进地展开, <0…0>。



## how

###  1. 优化问题

![image-20190531150749249](readme/21.00-03-优化问题.png)

![image-20190531150857554](readme/21.00-03-损失函数.png)

![image-20190531150924019](readme/21.00-03-常用的优化器.png)

#### 接下来 构造优化算法

```python
TRAINING_STEPS = 15
theta = torch.empty(DIM)
torch.nn.init.uniform_(theta,a=-1,b=1.0) 
theta_init = torch.tensor(theta,dtype=torch.float32,requires_grad=True)

def learn(optimizee,unroll_train_steps,retain_graph_flag=False,reset_theta = False): 
    """retain_graph_flag=False   PyTorch 默认每次loss_backward后 释放动态图
    #  reset_theta = False     默认每次学习前 不随机初始化参数"""
    
    if reset_theta == True:
        theta_new = torch.empty(DIM)
        torch.nn.init.uniform_(theta_new,a=-1,b=1.0) 
        theta_init_new = torch.tensor(theta,dtype=torch.float32,requires_grad=True)
        x = theta_init_new
    else:
        x = theta_init
        
    global_loss_graph = 0 #这个是为LSTM优化器求所有loss相加产生计算图准备的
    state = None
    x.requires_grad = True
    if optimizee.__name__ !='Adam':
        losses = []
        for i in range(unroll_train_steps):
            x.requires_grad = True
            
            loss = f(x)
            
            #global_loss_graph += (0.8*torch.log10(torch.Tensor([i]))+1)*loss
            
            global_loss_graph += loss
            
            #print(loss)
            loss.backward(retain_graph=retain_graph_flag) # 默认为False,当优化LSTM设置为True
            update, state = optimizee(x.grad, state)
            losses.append(loss)
            
            #这个操作 直接把x中包含的图给释放了，
           
            x = x + update
            
            x = x.detach_()
            #这个操作 直接把x中包含的图给释放了，
            #那传递给下次训练的x从子节点变成了叶节点，那么梯度就不能沿着这个路回传了，        
            #之前写这一步是因为这个子节点在下一次迭代不可以求导，那么应该用x.retain_grad()这个操作，
            #然后不需要每次新的的开始给x.requires_grad = True
            
            #x.retain_grad()
            #print(x.retain_grad())
            
            
        #print(x)
        return losses ,global_loss_graph 
    
    else:
        losses = []
        x.requires_grad = True
        optimizee= torch.optim.Adam( [x],lr=0.1 )
        
        for i in range(unroll_train_steps):
            
            optimizee.zero_grad()
            loss = f(x)
            global_loss_graph += loss
            
            loss.backward(retain_graph=retain_graph_flag)
            optimizee.step()
            losses.append(loss.detach_())
        #print(x)
        return losses,global_loss_graph 


```

#### 对比不同优化器的优化效果

```python
import matplotlib
import matplotlib.pyplot as plt
%matplotlib inline
import numpy as np

T = np.arange(TRAINING_STEPS)
for _ in range(1): 
    
    sgd_losses, sgd_sum_loss = learn(SGD,TRAINING_STEPS,reset_theta=True)
    rms_losses, rms_sum_loss = learn(RMS,TRAINING_STEPS,reset_theta=True)
    adam_losses, adam_sum_loss = learn(Adam,TRAINING_STEPS,reset_theta=True)
    p1, = plt.plot(T, sgd_losses, label='SGD')
    p2, = plt.plot(T, rms_losses, label='RMS')
    p3, = plt.plot(T, adam_losses, label='Adam')
    plt.legend(handles=[p1, p2, p3])
    plt.title('Losses')
    plt.show()
    print("sum_loss:sgd={},rms={},adam={}".format(sgd_sum_loss,rms_sum_loss,adam_sum_loss ))

```

![image-20190531151122876](readme/21.00-03-不同优化器的效果.png)

通过上述实验可以发现，这些优化器都可以发挥作用，似乎RMS表现更加优越一些，不过这并不代表RMS就比其他的好,可能这个优化问题还是较为简单，调整要优化的函数，可能就会看到不同的结果。

### 2. Meta-optimizer ：从手工设计优化器迈步到自动设计优化器

![image-20190531151234493](readme/21.00-03-元优化.png)

![image-20190531152124545](readme/21.00-03-构建LSTM优化器.png)

![image-20190531155001915](readme/21.00-03-构建LSTM优化器-02.png)

![image-20190531155036579](readme/21.00-03-构建LSTM优化器-03.png)

#### 好了，看一下我们使用刚刚初始化的LSTM优化器后的优化结果

```python
import matplotlib
import matplotlib.pyplot as plt
%matplotlib inline
import numpy as np

x = np.arange(TRAINING_STEPS)

    
for _ in range(1): 
    
    sgd_losses, sgd_sum_loss = learn(SGD,TRAINING_STEPS,reset_theta=True)
    rms_losses, rms_sum_loss = learn(RMS,TRAINING_STEPS,reset_theta=True)
    adam_losses, adam_sum_loss = learn(Adam,TRAINING_STEPS,reset_theta=True)
    lstm_losses,lstm_sum_loss = learn(LSTM_Optimizee,TRAINING_STEPS,reset_theta=True,retain_graph_flag = True)
    p1, = plt.plot(T, sgd_losses, label='SGD')
    p2, = plt.plot(T, rms_losses, label='RMS')
    p3, = plt.plot(T, adam_losses, label='Adam')
    p4, = plt.plot(x, lstm_losses, label='LSTM')
    p1.set_dashes([2, 2, 2, 2])  # 2pt line, 2pt break, 10pt line, 2pt break
    p2.set_dashes([4, 2, 8, 2])  # 2pt line, 2pt break, 10pt line, 2pt break
    p3.set_dashes([3, 2, 10, 2])  # 2pt line, 2pt break, 10pt line, 2pt break
    #plt.yscale('log')
    plt.legend(handles=[p1, p2, p3, p4])
    plt.title('Losses')
    plt.show()
    print("sum_loss:sgd={},rms={},adam={},lstm={}".format(sgd_sum_loss,rms_sum_loss,adam_sum_loss,lstm_sum_loss ))

```

![image-20190531155154212](readme/21.00-03-构建LSTM优化器-04.png)

![image-20190531155325383](readme/21.00-03-构建LSTM优化器-05.png)

### 3 通过梯度下降法来优化优化器

```python
Global_Train_Steps = 2

def global_training(optimizee):
    global_loss_list = []    
    adam_global_optimizer = torch.optim.Adam(optimizee.parameters(),lr = 0.0001)
    _,global_loss_1 = learn(LSTM_Optimizee,TRAINING_STEPS,retain_graph_flag =True ,reset_theta = True)
    
    #print(global_loss_1)
    
    for i in range(Global_Train_Steps):    
        _,global_loss = learn(LSTM_Optimizee,TRAINING_STEPS,retain_graph_flag =True ,reset_theta = False)       
        #adam_global_optimizer.zero_grad()
        print('xxx',[(z.grad,z.requires_grad) for z in optimizee.parameters()  ])
        #print(i,global_loss)
        global_loss.backward() #每次都是优化这个固定的图，不可以释放动态图的缓存
        #print('xxx',[(z.grad,z.requires_grad) for z in optimizee.parameters()  ])
        adam_global_optimizer.step()
        print('xxx',[(z.grad,z.requires_grad) for z in optimizee.parameters()  ])
        global_loss_list.append(global_loss.detach_())
        
    #print(global_loss)
    return global_loss_list

# 要把图放进函数体内，直接赋值的话图会丢失
# 优化optimizee
global_loss_list = global_training(lstm)

```

```python
xxx [(None, True), (None, True), (None, True), (None, True), (None, True), (None, True), (None, True), (None, True)]
xxx [(None, True), (None, True), (None, True), (None, True), (None, True), (None, True), (None, True), (None, True)]
xxx [(None, True), (None, True), (None, True), (None, True), (None, True), (None, True), (None, True), (None, True)]
xxx [(None, True), (None, True), (None, True), (None, True), (None, True), (None, True), (None, True), (None, True)]

```

#### 为什么loss值没有改变？为什么LSTM参数的梯度不存在的？

* 通过分析推理，我发现了LSTM参数的梯度为None,那么反向传播就完全没有更新LSTM的参数！

* 为什么参数的梯度为None呢，优化器并没有更新指定的LSTM的模型参数，一定是什么地方出了问题，我想了好久，还是做一些简单的实验来找一找问题吧。

> ps: 其实写代码做实验的过程，也体现了人类本身学会学习的高级能力，那就是：通过实验来实现想法时，实验结果往往和预期差别很大，那一定有什么地方出了问题，盲目地大量试错法可能找不到真正问题所在，如何找到问题所在并解决，就是一种学会如何学习的能力，也是一种强化学习的能力。这里我采用的人类智能是：以小见大法。
>
> In a word , if we want the machine achieving to AGI, it must imiate human’s ability of reasoning and finding where the problem is and figuring out how to solve the problem. Meta Learning contains this idea.

```python
import torch
z= torch.empty(2)
torch.nn.init.uniform_(z , -2, 2)
z.requires_grad = True
z.retain_grad()
def f(z):
    return (z*z).sum()

optimizer = torch.optim.Adam([z],lr=0.01)
grad =[]
losses= []
zgrad =[]

for i in range(2):
    optimizer.zero_grad()
    q = f(z)
    loss = q**2
    #z.retain_grad()
    loss.backward(retain_graph = True)
    optimizer.step()
    #print(x,x.grad,loss,)
    
    loss.retain_grad()
    print(q.grad,q.requires_grad)
    grad.append((z.grad))
    losses.append(loss)
    zgrad.append(q.grad)
    
print(grad)
print(losses)
print(zgrad)
```

```python
None True
None True
[tensor([-44.4396, -36.7740]), tensor([-44.4396, -36.7740])]
[tensor(35.9191, grad_fn=<PowBackward0>), tensor(35.0999, grad_fn=<PowBackward0>)]
[None, None]
```

#### 问题出在哪里？

* 经过多方面的实验修改，我发现LSTM的参数在每个周期内BPTT的周期内，并没有产生梯度！！怎么回事呢？我做了上面的小实验。
* 可以看到z.grad = None,但是z.requres_grad = True，z变量作为x变量的子节点，其在计算图中的梯度没有被保留或者没办法获取，那么我就应该通过修改一些PyTorch的代码，使得计算图中的叶子节点的梯度得以存在。然后我找到了retain_grad()这个函数，实验证明，它必须在backward()之前使用才能保存中间叶子节点的梯度！这样的方法也就适合于LSTM优化器模型参数的更新了吧？

* 那么如何保留LSTM的参数在每个周期中产生的梯度是接下来要修改的！

* 这是因为我计算loss = f(x)，然后loss.backward() 这里的loss计算并没有和LSTM产生关系，我先来想一想loss和LSTM的关系在哪里？

论文里有一张图，可以作为参考：

![image-20190531160609964](readme/21.00-03-构建LSTM优化器-06.png)

#### LSTM参数的梯度来自于每次输出的“update”的梯度 update的梯度包含在生成的下一次迭代的参数x的梯度中

![image-20190531161023397](readme/21.00-03-构建LSTM优化器-07.png)

```python
def learn(optimizee,unroll_train_steps,retain_graph_flag=False,reset_theta = False): 
    """retain_graph_flag=False   默认每次loss_backward后 释放动态图
    #  reset_theta = False     默认每次学习前 不随机初始化参数"""
    
    if reset_theta == True:
        theta_new = torch.empty(DIM)
        torch.nn.init.uniform_(theta_new,a=-1,b=1.0) 
        theta_init_new = torch.tensor(theta,dtype=torch.float32,requires_grad=True)
        x = theta_init_new
    else:
        x = theta_init
        
    global_loss_graph = 0 #这个是为LSTM优化器求所有loss相加产生计算图准备的
    state = None
    x.requires_grad = True
    if optimizee.__name__ !='Adam':
        losses = []
        for i in range(unroll_train_steps):
            
            loss = f(x)
            
            #global_loss_graph += torch.exp(torch.Tensor([-i/20]))*loss
            #global_loss_graph += (0.8*torch.log10(torch.Tensor([i+1]))+1)*loss
            global_loss_graph += loss
            
            
            loss.backward(retain_graph=retain_graph_flag) # 默认为False,当优化LSTM设置为True
            update, state = optimizee(x.grad, state)
            losses.append(loss)
           
            x = x + update
            
            # x = x.detach_()
            #这个操作 直接把x中包含的图给释放了，
            #那传递给下次训练的x从子节点变成了叶节点，那么梯度就不能沿着这个路回传了，        
            #之前写这一步是因为这个子节点在下一次迭代不可以求导，那么应该用x.retain_grad()这个操作，
            #然后不需要每次新的的开始给x.requires_grad = True
            
            x.retain_grad()
            #print(x.retain_grad())
            
            
        #print(x)
        return losses ,global_loss_graph 
    
    else:
        losses = []
        x.requires_grad = True
        optimizee= torch.optim.Adam( [x],lr=0.1 )
        
        for i in range(unroll_train_steps):
            
            optimizee.zero_grad()
            loss = f(x)
            global_loss_graph += loss
            
            loss.backward(retain_graph=retain_graph_flag)
            optimizee.step()
            losses.append(loss.detach_())
        #print(x)
        return losses,global_loss_graph 
    
Global_Train_Steps = 1000

def global_training(optimizee):
    global_loss_list = []    
    adam_global_optimizer = torch.optim.Adam([{'params':optimizee.parameters()},{'params':Linear.parameters()}],lr = 0.0001)
    _,global_loss_1 = learn(LSTM_Optimizee,TRAINING_STEPS,retain_graph_flag =True ,reset_theta = True)
    print(global_loss_1)
    for i in range(Global_Train_Steps):    
        _,global_loss = learn(LSTM_Optimizee,TRAINING_STEPS,retain_graph_flag =True ,reset_theta = False)       
        adam_global_optimizer.zero_grad()
        
        #print(i,global_loss)
        global_loss.backward() #每次都是优化这个固定的图，不可以释放动态图的缓存
        #print('xxx',[(z,z.requires_grad) for z in optimizee.parameters()  ])
        adam_global_optimizer.step()
        #print('xxx',[(z.grad,z.requires_grad) for z in optimizee.parameters()  ])
        global_loss_list.append(global_loss.detach_())
        
    print(global_loss)
    return global_loss_list

# 要把图放进函数体内，直接赋值的话图会丢失
# 优化optimizee
global_loss_list = global_training(lstm)

```

![image-20190531161804659](readme/21.00-03-构建LSTM优化器-08.png)

```python
import matplotlib
import matplotlib.pyplot as plt
%matplotlib inline
import numpy as np
STEPS = 15
x = np.arange(STEPS)

    
for _ in range(2): 
    
    sgd_losses, sgd_sum_loss = learn(SGD,STEPS,reset_theta=True)
    rms_losses, rms_sum_loss = learn(RMS,STEPS,reset_theta=True)
    adam_losses, adam_sum_loss = learn(Adam,STEPS,reset_theta=True)
    lstm_losses,lstm_sum_loss = learn(LSTM_Optimizee,STEPS,reset_theta=True,retain_graph_flag = True)
    p1, = plt.plot(x, sgd_losses, label='SGD')
    p2, = plt.plot(x, rms_losses, label='RMS')
    p3, = plt.plot(x, adam_losses, label='Adam')
    p4, = plt.plot(x, lstm_losses, label='LSTM')
    p1.set_dashes([2, 2, 2, 2])  # 2pt line, 2pt break, 10pt line, 2pt break
    p2.set_dashes([4, 2, 8, 2])  # 2pt line, 2pt break, 10pt line, 2pt break
    p3.set_dashes([3, 2, 10, 2])  # 2pt line, 2pt break, 10pt line, 2pt break
    plt.legend(handles=[p1, p2, p3, p4])
    #plt.yscale('log')
    plt.title('Losses')
    plt.show()
    print("sum_loss:sgd={},rms={},adam={},lstm={}".format(sgd_sum_loss,rms_sum_loss,adam_sum_loss,lstm_sum_loss ))

```

![image-20190531161849078](readme/21.00-03-构建LSTM优化器-09.png)

```python
import matplotlib
import matplotlib.pyplot as plt
%matplotlib inline
import numpy as np
STEPS = 50
x = np.arange(STEPS)

    
for _ in range(1): 
    
    sgd_losses, sgd_sum_loss = learn(SGD,STEPS,reset_theta=True)
    rms_losses, rms_sum_loss = learn(RMS,STEPS,reset_theta=True)
    adam_losses, adam_sum_loss = learn(Adam,STEPS,reset_theta=True)
    lstm_losses,lstm_sum_loss = learn(LSTM_Optimizee,STEPS,reset_theta=True,retain_graph_flag = True)
    p1, = plt.plot(x, sgd_losses, label='SGD')
    p2, = plt.plot(x, rms_losses, label='RMS')
    p3, = plt.plot(x, adam_losses, label='Adam')
    p4, = plt.plot(x, lstm_losses, label='LSTM')
    plt.legend(handles=[p1, p2, p3, p4])
    #plt.yscale('log')
    plt.title('Losses')
    plt.show()
    print("sum_loss:sgd={},rms={},adam={},lstm={}".format(sgd_sum_loss,rms_sum_loss,adam_sum_loss,lstm_sum_loss ))

```

![image-20190531161944505](readme/21.00-03-构建LSTM优化器-10.png)

![image-20190531162011948](readme/21.00-03-构建LSTM优化器-11.png)

```python
Layers = 2
Hidden_nums = 20

Input_DIM = DIM
Output_DIM = DIM
# "coordinate-wise" RNN 
#lstm1=torch.nn.LSTM(Input_DIM*2,Hidden_nums ,Layers)
#Linear = torch.nn.Linear(Hidden_nums,Output_DIM)


class LSTM_Optimizee_Model(torch.nn.Module):
    """LSTM优化器"""
    
    def __init__(self,input_size,output_size, hidden_size, num_stacks, batchsize, preprocess = True ,p = 10 ,output_scale = 1):
        super(LSTM_Optimizee_Model,self).__init__()
        self.preprocess_flag = preprocess
        self.p = p
        self.output_scale = output_scale #论文
        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_stacks)
        self.Linear = torch.nn.Linear(hidden_size,output_size)
        #elf.lstm = torch.nn.LSTM(10, 20,2)
        #elf.Linear = torch.nn.Linear(20,10)
    
    def LogAndSign_Preprocess_Gradient(self,gradients):
        """
        Args:
          gradients: `Tensor` of gradients with shape `[d_1, ..., d_n]`.
          p       : `p` > 0 is a parameter controlling how small gradients are disregarded 
        Returns:
          `Tensor` with shape `[d_1, ..., d_n-1, 2 * d_n]`. The first `d_n` elements
          along the nth dimension correspond to the `log output` \in [-1,1] and the remaining
          `d_n` elements to the `sign output`.
        """
        p  = self.p
        log = torch.log(torch.abs(gradients))
        clamp_log = torch.clamp(log/p , min = -1.0,max = 1.0)
        clamp_sign = torch.clamp(torch.exp(torch.Tensor(p))*gradients, min = -1.0, max =1.0)
        return torch.cat((clamp_log,clamp_sign),dim = -1) #在gradients的最后一维input_dims拼接
    
    def Output_Gradient_Increment_And_Update_LSTM_Hidden_State(self, input_gradients, prev_state):
        """LSTM的核心操作"""
        if prev_state is None: #init_state
            prev_state = (torch.zeros(Layers,batchsize,Hidden_nums),
                         torch.zeros(Layers,batchsize,Hidden_nums))
        
        update , next_state = self.lstm(input_gradients, prev_state)
        
        update = Linear(update) * self.output_scale #因为LSTM的输出是当前步的Hidden，需要变换到output的相同形状上 
        return update, next_state
    
    def forward(self,gradients, prev_state):
       
        #LSTM的输入为梯度，pytorch要求torch.nn.lstm的输入为（1，batchsize,input_dim）
        #原gradient.size()=torch.size[5] ->[1,1,5]
        gradients = gradients.unsqueeze(0).unsqueeze(0)
        if self.preprocess_flag == True:
            gradients = self.LogAndSign_Preprocess_Gradient(gradients)
        
        update , next_state = self.Output_Gradient_Increment_And_Update_LSTM_Hidden_State(gradients , prev_state)
        
        # Squeeze to make it a single batch again.[1,1,5]->[5]
        update = update.squeeze().squeeze()
        return update , next_state

LSTM_Optimizee = LSTM_Optimizee_Model(Input_DIM*2, Output_DIM, Hidden_nums ,Layers , batchsize=1,)
    

grads = torch.randn(10)*10
print(grads.size())

update,state =  LSTM_Optimizee(grads,None)
print(update.size(),)

```

编写成功！
执行！

```python
def learn(optimizee,unroll_train_steps,retain_graph_flag=False,reset_theta = False): 
    """retain_graph_flag=False   默认每次loss_backward后 释放动态图
    #  reset_theta = False     默认每次学习前 不随机初始化参数"""
    
    if reset_theta == True:
        theta_new = torch.empty(DIM)
        torch.nn.init.uniform_(theta_new,a=-1,b=1.0) 
        theta_init_new = torch.tensor(theta,dtype=torch.float32,requires_grad=True)
        x = theta_init_new
    else:
        x = theta_init
        
    global_loss_graph = 0 #这个是为LSTM优化器求所有loss相加产生计算图准备的
    state = None
    x.requires_grad = True
    if optimizee!='Adam':
        losses = []
        for i in range(unroll_train_steps):     
            loss = f(x)    
            #global_loss_graph += torch.exp(torch.Tensor([-i/20]))*loss
            #global_loss_graph += (0.8*torch.log10(torch.Tensor([i+1]))+1)*loss
            global_loss_graph += loss
           # print('loss{}:'.format(i),loss)
            loss.backward(retain_graph=retain_graph_flag) # 默认为False,当优化LSTM设置为True
            
            update, state = optimizee(x.grad, state)
           #print(update)
            losses.append(loss)     
            x = x + update  
            x.retain_grad()
        return losses ,global_loss_graph 
    
    else:
        losses = []
        x.requires_grad = True
        optimizee= torch.optim.Adam( [x],lr=0.1 )
        
        for i in range(unroll_train_steps):
            
            optimizee.zero_grad()
            loss = f(x)
            
            global_loss_graph += loss
            
            loss.backward(retain_graph=retain_graph_flag)
            optimizee.step()
            losses.append(loss.detach_())
        #print(x)
        return losses,global_loss_graph 
    
Global_Train_Steps = 100

def global_training(optimizee):
    global_loss_list = []    
    adam_global_optimizer = torch.optim.Adam(optimizee.parameters(),lr = 0.0001)
    _,global_loss_1 = learn(optimizee,TRAINING_STEPS,retain_graph_flag =True ,reset_theta = True)
    print(global_loss_1)
    for i in range(Global_Train_Steps):    
        _,global_loss = learn(optimizee,TRAINING_STEPS,retain_graph_flag =True ,reset_theta = False)       
        adam_global_optimizer.zero_grad()
        
        #print(i,global_loss)
        global_loss.backward() #每次都是优化这个固定的图，不可以释放动态图的缓存
        #print('xxx',[(z,z.requires_grad) for z in optimizee.parameters()  ])
        adam_global_optimizer.step()
        #print('xxx',[(z.grad,z.requires_grad) for z in optimizee.parameters()  ])
        global_loss_list.append(global_loss.detach_())
        
    print(global_loss)
    return global_loss_list

# 要把图放进函数体内，直接赋值的话图会丢失
# 优化optimizee
global_loss_list = global_training(LSTM_Optimizee)

```

![image-20190531162112924](readme/21.00-03-构建LSTM优化器-12.png)

```python
import matplotlib
import matplotlib.pyplot as plt
%matplotlib inline
import numpy as np
STEPS = 30
x = np.arange(STEPS)

Adam = 'Adam'  
for _ in range(1): 
    
    sgd_losses, sgd_sum_loss = learn(SGD,STEPS,reset_theta=True)
    rms_losses, rms_sum_loss = learn(RMS,STEPS,reset_theta=True)
    adam_losses, adam_sum_loss = learn(Adam,STEPS,reset_theta=True)
    lstm_losses,lstm_sum_loss = learn(LSTM_Optimizee,STEPS,reset_theta=True,retain_graph_flag = True)
    p1, = plt.plot(x, sgd_losses, label='SGD')
    p2, = plt.plot(x, rms_losses, label='RMS')
    p3, = plt.plot(x, adam_losses, label='Adam')
    p4, = plt.plot(x, lstm_losses, label='LSTM')
    p1.set_dashes([2, 2, 2, 2])  # 2pt line, 2pt break, 10pt line, 2pt break
    p2.set_dashes([4, 2, 8, 2])  # 2pt line, 2pt break, 10pt line, 2pt break
    p3.set_dashes([3, 2, 10, 2])  # 2pt line, 2pt break, 10pt line, 2pt break
    plt.legend(handles=[p1, p2, p3, p4])
    plt.title('Losses')
    plt.show()
    print("sum_loss:sgd={},rms={},adam={},lstm={}".format(sgd_sum_loss,rms_sum_loss,adam_sum_loss,lstm_sum_loss ))

```

![image-20190531162153138](readme/21.00-03-构建LSTM优化器-13.png)

![image-20190531162328786](readme/21.00-03-构建LSTM优化器-14.png)

![image-20190531162353445](readme/21.00-03-构建LSTM优化器-15.png)

```python
# coding: utf-8

# Learning to learn by gradient descent by gradient descent
# =========================#

# https://arxiv.org/abs/1611.03824
# https://yangsenius.github.io/blog/LSTM_Meta/
# https://github.com/yangsenius/learning-to-learn-by-pytorch
# author：yangsen
# #### “通过梯度下降来学习如何通过梯度下降学习”
# #### 要让优化器学会这样   "为了更好地得到，要先去舍弃"  这样类似的知识！

import torch
import torch.nn as nn
from timeit import default_timer as timer
#####################      优化问题   ##########################
USE_CUDA = False
DIM = 10
batchsize = 128

if torch.cuda.is_available():
    USE_CUDA = True  
USE_CUDA = False  


print('\n\nUSE_CUDA = {}\n\n'.format(USE_CUDA))
 

def f(W,Y,x):
    """quadratic function : f(\theta) = \|W\theta - y\|_2^2"""
    if USE_CUDA:
        W = W.cuda()
        Y = Y.cuda()
        x = x.cuda()

    return ((torch.matmul(W,x.unsqueeze(-1)).squeeze()-Y)**2).sum(dim=1).mean(dim=0)

###############################################################

######################    手工的优化器   ###################

def SGD(gradients, state, learning_rate=0.001):
   
    return -gradients*learning_rate, state

def RMS(gradients, state, learning_rate=0.01, decay_rate=0.9):
    if state is None:
        state = torch.zeros(DIM)
        if USE_CUDA == True:
            state = state.cuda()
            
    state = decay_rate*state + (1-decay_rate)*torch.pow(gradients, 2)
    update = -learning_rate*gradients / (torch.sqrt(state+1e-5))
    return update, state

def adam():
    return torch.optim.Adam()

##########################################################


#####################    自动 LSTM 优化器模型  ##########################
class LSTM_Optimizee_Model(torch.nn.Module):
    """LSTM优化器"""
    
    def __init__(self,input_size,output_size, hidden_size, num_stacks, batchsize, preprocess = True ,p = 10 ,output_scale = 1):
        super(LSTM_Optimizee_Model,self).__init__()
        self.preprocess_flag = preprocess
        self.p = p
        self.input_flag = 2
        if preprocess != True:
             self.input_flag = 1
        self.output_scale = output_scale #论文
        self.lstm = torch.nn.LSTM(input_size*self.input_flag, hidden_size, num_stacks)
        self.Linear = torch.nn.Linear(hidden_size,output_size) #1-> output_size
        
    def LogAndSign_Preprocess_Gradient(self,gradients):
        """
        Args:
          gradients: `Tensor` of gradients with shape `[d_1, ..., d_n]`.
          p       : `p` > 0 is a parameter controlling how small gradients are disregarded 
        Returns:
          `Tensor` with shape `[d_1, ..., d_n-1, 2 * d_n]`. The first `d_n` elements
          along the nth dimension correspond to the `log output` \in [-1,1] and the remaining
          `d_n` elements to the `sign output`.
        """
        p  = self.p
        log = torch.log(torch.abs(gradients))
        clamp_log = torch.clamp(log/p , min = -1.0,max = 1.0)
        clamp_sign = torch.clamp(torch.exp(torch.Tensor(p))*gradients, min = -1.0, max =1.0)
        return torch.cat((clamp_log,clamp_sign),dim = -1) #在gradients的最后一维input_dims拼接
    
    def Output_Gradient_Increment_And_Update_LSTM_Hidden_State(self, input_gradients, prev_state):
        """LSTM的核心操作
        coordinate-wise LSTM """
        if prev_state is None: #init_state
            prev_state = (torch.zeros(Layers,batchsize,Hidden_nums),
                            torch.zeros(Layers,batchsize,Hidden_nums))
            if USE_CUDA :
                 prev_state = (torch.zeros(Layers,batchsize,Hidden_nums).cuda(),
                            torch.zeros(Layers,batchsize,Hidden_nums).cuda())
         			
        update , next_state = self.lstm(input_gradients, prev_state)
        update = self.Linear(update) * self.output_scale #因为LSTM的输出是当前步的Hidden，需要变换到output的相同形状上 
        return update, next_state
    
    def forward(self,input_gradients, prev_state):
        if USE_CUDA:
            input_gradients = input_gradients.cuda()
        #LSTM的输入为梯度，pytorch要求torch.nn.lstm的输入为（1，batchsize,input_dim）
        #原gradient.size()=torch.size[5] ->[1,1,5]
        gradients = input_gradients.unsqueeze(0)
      
        if self.preprocess_flag == True:
            gradients = self.LogAndSign_Preprocess_Gradient(gradients)
      
        update , next_state = self.Output_Gradient_Increment_And_Update_LSTM_Hidden_State(gradients , prev_state)
        # Squeeze to make it a single batch again.[1,1,5]->[5]
        update = update.squeeze().squeeze()
       
        return update , next_state
    
#################   优化器模型参数  ##############################
Layers = 2
Hidden_nums = 20
Input_DIM = DIM
Output_DIM = DIM
output_scale_value=1

#######   构造一个优化器  #######
LSTM_Optimizee = LSTM_Optimizee_Model(Input_DIM, Output_DIM, Hidden_nums ,Layers , batchsize=batchsize,\
                preprocess=False,output_scale=output_scale_value)
print(LSTM_Optimizee)

if USE_CUDA:
    LSTM_Optimizee = LSTM_Optimizee.cuda()
   

######################  优化问题目标函数的学习过程   ###############


class Learner( object ):
    """
    Args :
        `f` : 要学习的问题
        `optimizee` : 使用的优化器
        `train_steps` : 对于其他SGD,Adam等是训练周期，对于LSTM训练时的展开周期
        `retain_graph_flag=False`  : 默认每次loss_backward后 释放动态图
        `reset_theta = False `  :  默认每次学习前 不随机初始化参数
        `reset_function_from_IID_distirbution = True` : 默认从分布中随机采样函数 

    Return :
        `losses` : reserves each loss value in each iteration
        `global_loss_graph` : constructs the graph of all Unroll steps for LSTM's BPTT 
    """
    def __init__(self,    f ,   optimizee,  train_steps ,  
                                            eval_flag = False,
                                            retain_graph_flag=False,
                                            reset_theta = False ,
                                            reset_function_from_IID_distirbution = True):
        self.f = f
        self.optimizee = optimizee
        self.train_steps = train_steps
        #self.num_roll=num_roll
        self.eval_flag = eval_flag
        self.retain_graph_flag = retain_graph_flag
        self.reset_theta = reset_theta
        self.reset_function_from_IID_distirbution = reset_function_from_IID_distirbution  
        self.init_theta_of_f()
        self.state = None

        self.global_loss_graph = 0 #这个是为LSTM优化器求所有loss相加产生计算图准备的
        self.losses = []   # 保存每个训练周期的loss值

    def init_theta_of_f(self,):  
        ''' 初始化 优化问题 f 的参数 '''
        self.DIM = 10
        self.batchsize = 128
        self.W = torch.randn(batchsize,DIM,DIM) #代表 已知的数据 # 独立同分布的标准正太分布
        self.Y = torch.randn(batchsize,DIM)
        self.x = torch.zeros(self.batchsize,self.DIM)
        self.x.requires_grad = True
        if USE_CUDA:
            self.W = self.W.cuda()
            self.Y = self.Y.cuda()
            self.x = self.x.cuda()
        
            
    def Reset_Or_Reuse(self , x , W , Y , state, num_roll):
        ''' re-initialize the `W, Y, x , state`  at the begining of each global training
            IF `num_roll` == 0    '''

        reset_theta =self.reset_theta
        reset_function_from_IID_distirbution = self.reset_function_from_IID_distirbution

       
        if num_roll == 0 and reset_theta == True:
            theta = torch.zeros(batchsize,DIM)
           
            theta_init_new = torch.tensor(theta,dtype=torch.float32,requires_grad=True)
            x = theta_init_new
            
            
        ################   每次全局训练迭代，从独立同分布的Normal Gaussian采样函数     ##################
        if num_roll == 0 and reset_function_from_IID_distirbution == True :
            W = torch.randn(batchsize,DIM,DIM) #代表 已知的数据 # 独立同分布的标准正太分布
            Y = torch.randn(batchsize,DIM)     #代表 数据的标签 #  独立同分布的标准正太分布
         
            
        if num_roll == 0:
            state = None
            print('reset W, x , Y, state ')
            
        if USE_CUDA:
            W = W.cuda()
            Y = Y.cuda()
            x = x.cuda()
            x.retain_grad()
          
            
        return  x , W , Y , state

    def __call__(self, num_roll=0) : 
        '''
        Total Training steps = Unroll_Train_Steps * the times of  `Learner` been called
        
        SGD,RMS,LSTM 用上述定义的
         Adam优化器直接使用pytorch里的，所以代码上有区分 后面可以完善！'''
        f  = self.f 
        x , W , Y , state =  self.Reset_Or_Reuse(self.x , self.W , self.Y , self.state , num_roll )
        self.global_loss_graph = 0   #每个unroll的开始需要 重新置零
        optimizee = self.optimizee
        print('state is None = {}'.format(state == None))
     
        if optimizee!='Adam':
            
            for i in range(self.train_steps):     
                loss = f(W,Y,x)
                #self.global_loss_graph += (0.8*torch.log10(torch.Tensor([i+1]))+1)*loss
                self.global_loss_graph += loss
              
                loss.backward(retain_graph=self.retain_graph_flag) # 默认为False,当优化LSTM设置为True
              
                update, state = optimizee(x.grad, state)
              
                self.losses.append(loss)
             
                x = x + update  
                x.retain_grad()
                update.retain_grad()
                
            if state is not None:
                self.state = (state[0].detach(),state[1].detach())
                
            return self.losses ,self.global_loss_graph 

        else: #Pytorch Adam

            x.detach_()
            x.requires_grad = True
            optimizee= torch.optim.Adam( [x],lr=0.1 )
            
            for i in range(self.train_steps):
                
                optimizee.zero_grad()
                loss = f(W,Y,x)
                
                self.global_loss_graph += loss
                
                loss.backward(retain_graph=self.retain_graph_flag)
                optimizee.step()
                self.losses.append(loss.detach_())
                
            return self.losses, self.global_loss_graph


#######   LSTM 优化器的训练过程 Learning to learn   ###############

def Learning_to_learn_global_training(optimizee, global_taining_steps, Optimizee_Train_Steps, UnRoll_STEPS, Evaluate_period ,optimizer_lr=0.1):
    """ Training the LSTM optimizee . Learning to learn

    Args:   
        `optimizee` : DeepLSTMCoordinateWise optimizee model
        `global_taining_steps` : how many steps for optimizer training o可以ptimizee
        `Optimizee_Train_Steps` : how many step for optimizee opimitzing each function sampled from IID.
        `UnRoll_STEPS` :: how many steps for LSTM optimizee being unrolled to construct a computing graph to BPTT.
    """
    global_loss_list = []
    Total_Num_Unroll = Optimizee_Train_Steps // UnRoll_STEPS
    adam_global_optimizer = torch.optim.Adam(optimizee.parameters(),lr = optimizer_lr)

    LSTM_Learner = Learner(f, optimizee, UnRoll_STEPS, retain_graph_flag=True, reset_theta=True,)
  #这里考虑Batchsize代表IID的话，那么就可以不需要每次都重新IID采样
  #即reset_function_from_IID_distirbution = False 否则为True

    best_sum_loss = 999999
    best_final_loss = 999999
    best_flag = False
    for i in range(Global_Train_Steps): 

        print('\n=======> global training steps: {}'.format(i))

        for num in range(Total_Num_Unroll):
            
            start = timer()
            _,global_loss = LSTM_Learner(num)   

            adam_global_optimizer.zero_grad()
            global_loss.backward() 
       
            adam_global_optimizer.step()
            # print('xxx',[(z.grad,z.requires_grad) for z in optimizee.lstm.parameters()  ])
            global_loss_list.append(global_loss.detach_())
            time = timer() - start
            #if i % 10 == 0:
            print('-> time consuming [{:.1f}s] optimizee train steps :  [{}] | Global_Loss = [{:.1f}] '\
                  .format(time,(num +1)* UnRoll_STEPS,global_loss,))

        if (i + 1) % Evaluate_period == 0:
            
            best_sum_loss, best_final_loss, best_flag  = evaluate(best_sum_loss,best_final_loss,best_flag , optimizer_lr)

    return global_loss_list,best_flag


def evaluate(best_sum_loss,best_final_loss, best_flag,lr):
    print('\n --> evalute the model')
    STEPS = 100
    LSTM_learner = Learner(f , LSTM_Optimizee, STEPS, eval_flag=True,reset_theta=True, retain_graph_flag=True)
    lstm_losses, sum_loss = LSTM_learner()
    try:
        best = torch.load('best_loss.txt')
    except IOError:
        print ('can not find best_loss.txt')
        pass
    else:
        best_sum_loss = best[0]
        best_final_loss = best[1]
        print("load_best_final_loss and sum_loss")
    if lstm_losses[-1] < best_final_loss and  sum_loss < best_sum_loss:
        best_final_loss = lstm_losses[-1]
        best_sum_loss =  sum_loss
        
        print('\n\n===> update new best of final LOSS[{}]: =  {}, best_sum_loss ={}'.format(STEPS, best_final_loss,best_sum_loss))
        torch.save(LSTM_Optimizee.state_dict(),'best_LSTM_optimizer.pth')
        torch.save([best_sum_loss ,best_final_loss,lr ],'best_loss.txt')
        best_flag = True
        
    return best_sum_loss, best_final_loss, best_flag 



```

![image-20190531162436510](readme/21.00-03-构建LSTM优化器-16.png)

```python
#############  注意：接上一片段的代码！！   #######################3#
##########################   before learning LSTM optimizee ###############################
import numpy as np
import matplotlib
import matplotlib.pyplot as plt

STEPS = 100
x = np.arange(STEPS)

Adam = 'Adam' #因为这里Adam使用Pytorch

for _ in range(1): 
   
    SGD_Learner = Learner(f , SGD, STEPS, eval_flag=True,reset_theta=True,)
    RMS_Learner = Learner(f , RMS, STEPS, eval_flag=True,reset_theta=True,)
    Adam_Learner = Learner(f , Adam, STEPS, eval_flag=True,reset_theta=True,)
    LSTM_learner = Learner(f , LSTM_Optimizee, STEPS, eval_flag=True,reset_theta=True,retain_graph_flag=True)

    sgd_losses, sgd_sum_loss = SGD_Learner()
    rms_losses, rms_sum_loss = RMS_Learner()
    adam_losses, adam_sum_loss = Adam_Learner()
    lstm_losses, lstm_sum_loss = LSTM_learner()

    p1, = plt.plot(x, sgd_losses, label='SGD')
    p2, = plt.plot(x, rms_losses, label='RMS')
    p3, = plt.plot(x, adam_losses, label='Adam')
    p4, = plt.plot(x, lstm_losses, label='LSTM')
    p1.set_dashes([2, 2, 2, 2])  # 2pt line, 2pt break, 10pt line, 2pt break
    p2.set_dashes([4, 2, 8, 2])  # 2pt line, 2pt break, 10pt line, 2pt break
    p3.set_dashes([3, 2, 10, 2])  # 2pt line, 2pt break, 10pt line, 2pt break
    plt.yscale('log')
    plt.legend(handles=[p1, p2, p3, p4])
    plt.title('Losses')
    plt.show()
    print("\n\nsum_loss:sgd={},rms={},adam={},lstm={}".format(sgd_sum_loss,rms_sum_loss,adam_sum_loss,lstm_sum_loss ))

```

```python
reset W, x , Y, state 
state is None = True
reset W, x , Y, state 
state is None = True
reset W, x , Y, state 
state is None = True
reset W, x , Y, state 
state is None = True
```

![image-20190531162532115](readme/21.00-03-构建LSTM优化器-17.png)

```python
#######   注意：接上一段的代码！！
#################### Learning to learn (优化optimizee) ######################
Global_Train_Steps = 1000 #可修改
Optimizee_Train_Steps = 100
UnRoll_STEPS = 20
Evaluate_period = 1 #可修改
optimizer_lr = 0.1 #可修改
global_loss_list ,flag = Learning_to_learn_global_training(   LSTM_Optimizee,
                                                        Global_Train_Steps,
                                                        Optimizee_Train_Steps,
                                                        UnRoll_STEPS,
                                                        Evaluate_period,
                                                          optimizer_lr)


######################################################################3#
##########################   show learning process results 
#torch.load('best_LSTM_optimizer.pth'))
#import numpy as np
#import matplotlib
#import matplotlib.pyplot as plt

#Global_T = np.arange(len(global_loss_list))
#p1, = plt.plot(Global_T, global_loss_list, label='Global_graph_loss')
#plt.legend(handles=[p1])
#plt.title('Training LSTM optimizee by gradient descent ')
#plt.show()

```

```python
=======> global training steps: 0
reset W, x , Y, state 
state is None = True
-> time consuming [0.2s] optimizee train steps :  [20] | Global_Loss = [4009.4] 
state is None = False
-> time consuming [0.3s] optimizee train steps :  [40] | Global_Loss = [21136.7] 
state is None = False
-> time consuming [0.2s] optimizee train steps :  [60] | Global_Loss = [136640.5] 
state is None = False
-> time consuming [0.2s] optimizee train steps :  [80] | Global_Loss = [4017.9] 
state is None = False
-> time consuming [0.2s] optimizee train steps :  [100] | Global_Loss = [9107.1] 


 --> evalute the model
reset W, x , Y, state 
state is None = True

...........
...........

```

输出结果已经省略大部分

#### 接下来看一下优化好的LSTM优化器模型和SGD，RMSProp，Adam的优化性能对比表现吧~

鸡冻

```python
###############  **注意： **接上一片段的代码****
######################################################################3#
##########################   show contrast results SGD,ADAM, RMS ,LSTM ###############################
import copy
import numpy as np
import matplotlib
import matplotlib.pyplot as plt

if flag ==True :
    print('\n==== > load best LSTM model')
    last_state_dict = copy.deepcopy(LSTM_Optimizee.state_dict())
    torch.save(LSTM_Optimizee.state_dict(),'final_LSTM_optimizer.pth')
    LSTM_Optimizee.load_state_dict( torch.load('best_LSTM_optimizer.pth'))
    
LSTM_Optimizee.load_state_dict(torch.load('best_LSTM_optimizer.pth'))
#LSTM_Optimizee.load_state_dict(torch.load('final_LSTM_optimizer.pth'))
STEPS = 100
x = np.arange(STEPS)

Adam = 'Adam' #因为这里Adam使用Pytorch

for _ in range(2): #可以多试几次测试实验，LSTM不稳定
    
    SGD_Learner = Learner(f , SGD, STEPS, eval_flag=True,reset_theta=True,)
    RMS_Learner = Learner(f , RMS, STEPS, eval_flag=True,reset_theta=True,)
    Adam_Learner = Learner(f , Adam, STEPS, eval_flag=True,reset_theta=True,)
    LSTM_learner = Learner(f , LSTM_Optimizee, STEPS, eval_flag=True,reset_theta=True,retain_graph_flag=True)

    
    sgd_losses, sgd_sum_loss = SGD_Learner()
    rms_losses, rms_sum_loss = RMS_Learner()
    adam_losses, adam_sum_loss = Adam_Learner()
    lstm_losses, lstm_sum_loss = LSTM_learner()

    p1, = plt.plot(x, sgd_losses, label='SGD')
    p2, = plt.plot(x, rms_losses, label='RMS')
    p3, = plt.plot(x, adam_losses, label='Adam')
    p4, = plt.plot(x, lstm_losses, label='LSTM')
    p1.set_dashes([2, 2, 2, 2])  # 2pt line, 2pt break, 10pt line, 2pt break
    p2.set_dashes([4, 2, 8, 2])  # 2pt line, 2pt break, 10pt line, 2pt break
    p3.set_dashes([3, 2, 10, 2])  # 2pt line, 2pt break, 10pt line, 2pt break
    #p4.set_dashes([2, 2, 10, 2])  # 2pt line, 2pt break, 10pt line, 2pt break
    plt.yscale('log')
    plt.legend(handles=[p1, p2, p3, p4])
    plt.title('Losses')
    plt.show()
    print("\n\nsum_loss:sgd={},rms={},adam={},lstm={}".format(sgd_sum_loss,rms_sum_loss,adam_sum_loss,lstm_sum_loss ))

```

![image-20190531162646337](readme/21.00-03-构建LSTM优化器-18.png)

![image-20190531162708379](readme/21.00-03-构建LSTM优化器-19.png)

### 4. 实验条件

![image-20190531162753904](readme/21.00-03-实验条件.png)

> 人可以从自身认识与客观存在的差异中学习，来不断的提升认知能力，这是最基本的学习能力。而另一种潜在不容易发掘，但却是更强大的能力–在学习中不断调整适应自身与外界的学习技巧或者规则–其实构建了我们更高阶的智能。比如，我们在学习知识时，我们总会先接触一些简单容易理解的基本概念，遇到一些理解起来困难或者十分抽象的概念时，我们往往不是采取强行记忆，即我们并不会立刻学习跟我们当前认知的偏差非常大的事物，而是把它先放到一边，继续学习更多简单的概念，直到有所“领悟”发现先前的困难概念变得容易理解

>心理学上，元认知被称作反省认知，指人对自我认知的认知。弗拉威尔称，元认知是关于个人自己认知过程的知识和调节这些过程的能力：对思维和学习活动的知识和控制。那么学会适应性地调整学习策略，也成为机器学习的一个研究课题，a most ordinary problem for machine learning is that although we expect to find the invariant pattern in all data, for an individual instance in a specified dataset，it has its own unique attribute, which requires the model taking different policy to understand them seperately .