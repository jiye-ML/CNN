* `dropout`的目标是在指数级数量的神经玩过上近似这个过程；
* `dropout`训练与`bagging`训练不太一样，在`bagging`的情况下，所有模型是独立的，`dropout`情况下，模型是共享参数的，其中每个模型继承的父神经网络参数的不同子集。
* 参数共享使得在有限可用的内存下代表指数数量的模型变得可能。
  ![](readme/13.08-01-dropout_01.png)

* `bagging`集成必须从所有成员的累积投票做一个预测。我们将这个过程称为推断。
* `dropout`的方式不能依赖于任何的特征，因为任何特征都有可能被丢弃，
* `dropOut`是用来防止过拟合，所以除非你的网络过拟合， 否则不要使用。